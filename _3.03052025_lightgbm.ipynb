{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8f899af2",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#########################################################################################################################\n",
    "# CALCUATE PREDICTION FOR NEXT GAME DAY #\n",
    "\n",
    "# Script 3 of 4\n",
    "# This script Calculates game predictions for the next NBA game day using historical data, rolling averages, and machine learning models,\n",
    "# and outputs results with probabilities.\n",
    "\n",
    "# Ensure `_2. 03012025_get_data_next_game_day.ipynb` is executed before running this script.\n",
    "#########################################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fb9592a4",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "ROLLING_WINDOW_SIZE = 8\n",
    "current_season = 2025"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bc0ca9f9",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "import os\n",
    "\n",
    "import lightgbm as lgb\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.feature_selection import SequentialFeatureSelector\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import glob\n",
    "import datetime\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "import subprocess\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eb240c70",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "today = (datetime.now()- timedelta(days=0)).strftime(\"%Y-%m-%d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4bb95111",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:10: SyntaxWarning: invalid escape sequence '\\P'\n",
      "<>:10: SyntaxWarning: invalid escape sequence '\\P'\n",
      "C:\\Users\\alexx\\AppData\\Local\\Temp\\ipykernel_20208\\3474221041.py:10: SyntaxWarning: invalid escape sequence '\\P'\n",
      "  open_office_path = \"C:\\Program Files (x86)\\OpenOffice 4\\program/scalc\"\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Constants\n",
    "target_folder = \"D:\\\\1. Python\\\\1. NBA Script\\\\2025\\\\Gathering_Data\\\\Next_Game\\\\\"\n",
    "STAT_DIR = \"D:\\\\1. Python\\\\1. NBA Script\\\\2025\\\\Gathering_Data\\\\Whole_Statistic\\\\\"\n",
    "\n",
    "df_path = os.path.join(STAT_DIR, f\"nba_games_{today}.csv\")\n",
    "\n",
    "directory_path = r\"D:\\1. Python\\1. NBA Script\\2025\\LightGBM\\1. 2025_Prediction\"\n",
    "dst_dir = r'C:\\_Laufwerk C\\11. Sorare\\NBA\\2025\\LightGBM'\n",
    "\n",
    "open_office_path = \"C:\\Program Files (x86)\\OpenOffice 4\\program/scalc\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d93c272d",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "home_team away_team  game_date\n",
      "      DEN       LAC 2025-05-03\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Define directory and date format\n",
    "# Check if file exists\n",
    "file_path = f\"{target_folder}games_df_{today}.csv\"\n",
    "if not os.path.exists(file_path):\n",
    "    # List files and pick the latest one\n",
    "    files = sorted(glob.glob(f\"{target_folder}games_df_*.csv\"))\n",
    "    if files:\n",
    "        file_path = files[-1]  # Use the latest available file\n",
    "        print(f\"Using the latest file: {file_path}\")\n",
    "    else:\n",
    "        print(\"No files found in the directory.\")\n",
    "        exit()\n",
    "\n",
    "# Proceed to read the file\n",
    "games_df = pd.read_csv(file_path, index_col=0)\n",
    "print(games_df.head(60).to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ada19e24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         fg   fga      fg%    3p   3pa      3p%    ft   fta      ft%   orb  \\\n",
      "mp.1                                                                         \n",
      "240.0  37.0  96.0  385.000  12.0  29.0  414.000  20.0  26.0  769.000  23.0   \n",
      "240.0  37.0  82.0  451.000   8.0  27.0  296.000  12.0  15.0    0.800   7.0   \n",
      "240.0  38.0  94.0  404.000   9.0  29.0    0.310  10.0  17.0  588.000  11.0   \n",
      "240.0  37.0  87.0  425.000   7.0  19.0  368.000  16.0  23.0  696.000   7.0   \n",
      "240.0  35.0  83.0  422.000   6.0  18.0  333.000  19.0  27.0  704.000   8.0   \n",
      "...     ...   ...      ...   ...   ...      ...   ...   ...      ...   ...   \n",
      "NaN    38.0  81.0    0.469   9.0  34.0    0.265  28.0  33.0    0.848   6.0   \n",
      "NaN    44.0  84.0    0.524  11.0  27.0    0.407   6.0   9.0    0.667  10.0   \n",
      "NaN    43.0  86.0    0.500  12.0  39.0    0.308  13.0  15.0    0.867   9.0   \n",
      "NaN    35.0  78.0    0.449  12.0  30.0    0.400  33.0  46.0    0.717  11.0   \n",
      "NaN    37.0  90.0    0.411  15.0  49.0    0.306  18.0  22.0    0.818  13.0   \n",
      "\n",
      "       ...  usg%_max_opp  ortg_max_opp  drtg_max_opp  team_opp  total_opp  \\\n",
      "mp.1   ...                                                                  \n",
      "240.0  ...          33.8         258.0         121.0       ATL         94   \n",
      "240.0  ...          23.6         132.0         104.0       DET        106   \n",
      "240.0  ...          34.6         162.0         104.0       CHI         97   \n",
      "240.0  ...          29.0         138.0         105.0       CLE         95   \n",
      "240.0  ...          43.7         206.0         104.0       GSW        111   \n",
      "...    ...           ...           ...           ...       ...        ...   \n",
      "NaN    ...          37.6         139.0         118.0       NYK        116   \n",
      "NaN    ...          30.2         155.0         128.0       LAC        111   \n",
      "NaN    ...          30.4         185.0         133.0       DEN        105   \n",
      "NaN    ...          51.4         235.0         126.0       GSW        107   \n",
      "NaN    ...          35.0         193.0         121.0       HOU        115   \n",
      "\n",
      "       home_opp  season                 date    won  Unnamed: 0  \n",
      "mp.1                                                             \n",
      "240.0         1    2016           2015-10-27   True         NaN  \n",
      "240.0         0    2016           2015-10-27  False         NaN  \n",
      "240.0         1    2016           2015-10-27  False         NaN  \n",
      "240.0         0    2016           2015-10-27   True         NaN  \n",
      "240.0         1    2016           2015-10-27  False         NaN  \n",
      "...         ...     ...                  ...    ...         ...  \n",
      "NaN           0    2025  2025-05-01 00:00:00  False         NaN  \n",
      "NaN           1    2025  2025-05-01 00:00:00  False         NaN  \n",
      "NaN           0    2025  2025-05-01 00:00:00   True         NaN  \n",
      "NaN           1    2025  2025-05-02 00:00:00   True         NaN  \n",
      "NaN           0    2025  2025-05-02 00:00:00  False         NaN  \n",
      "\n",
      "[24688 rows x 149 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alexx\\AppData\\Local\\Temp\\ipykernel_20208\\583120452.py:37: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df = df.groupby('team').apply(add_target)\n",
      "C:\\Users\\alexx\\AppData\\Local\\Temp\\ipykernel_20208\\583120452.py:40: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['target'].fillna(2, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Function to find the most recent file in the directory if the desired one is not available\n",
    "def get_latest_available_file(target_folder, prefix=\"nba_games_\", extension=\".csv\"):\n",
    "    \"\"\"Returns the latest available CSV file matching the pattern.\"\"\"\n",
    "    available_files = [f for f in os.listdir(target_folder) if f.startswith(prefix) and f.endswith(extension)]\n",
    "    if available_files:\n",
    "        latest_file = max(available_files, key=lambda f: os.path.getctime(os.path.join(target_folder, f)))\n",
    "        return os.path.join(target_folder, latest_file)\n",
    "    return None\n",
    "\n",
    "# Check if the specific file for today exists; if not, fallback to the most recent available file\n",
    "if not os.path.exists(df_path):\n",
    "    print(f\"File for {today} not found. Searching for the latest available file...\")\n",
    "    df_path = get_latest_available_file(DST_DIR)\n",
    "    if df_path:\n",
    "        print(f\"Using the latest available file: {df_path}\")\n",
    "    else:\n",
    "        raise FileNotFoundError(f\"No suitable file found in the directory: {DST_DIR}\")\n",
    "\n",
    "# Proceed with loading the data\n",
    "df = pd.read_csv(df_path, index_col=0)\n",
    "print(df)#.tail())  # Display a portion of the data\n",
    "\n",
    "# Function to add a target column\n",
    "def add_target(group):\n",
    "    \"\"\"Adds a target column to the DataFrame group based on the 'won' column.\"\"\"\n",
    "    group['target'] = group['won'].shift(-1)\n",
    "    return group\n",
    "\n",
    "def preprocess_nba_data():\n",
    "    # Load the data\n",
    "    df = pd.read_csv(df_path, index_col=0)\n",
    "    \n",
    "    # Sort by date\n",
    "    df = df.sort_values(\"date\")\n",
    "\n",
    "    # Apply the preprocessing function to each team group\n",
    "    df = df.groupby('team').apply(add_target)\n",
    "\n",
    "    # Handle missing values\n",
    "    df['target'].fillna(2, inplace=True)\n",
    "    df['target'] = df['target'].astype(int)\n",
    "\n",
    "    # Identify and remove columns with null values\n",
    "    nulls = pd.isnull(df).sum()\n",
    "    nulls = nulls[nulls > 0]\n",
    "    valid_columns = df.columns[~df.columns.isin(nulls.index)]\n",
    "    df = df[valid_columns].copy()\n",
    "\n",
    "    return df\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    df = preprocess_nba_data()\n",
    "\n",
    "    # Columns to be excluded from scaling\n",
    "    removed_columns = [\"season\", \"date\", \"won\", \"target\", \"team\", \"team_opp\"]\n",
    "\n",
    "    # Selecting columns that are not in the 'removed_columns' list\n",
    "    selected_columns = df.columns[~df.columns.isin(removed_columns)]\n",
    "\n",
    "    # Initialize the MinMaxScaler\n",
    "    scaler = MinMaxScaler()\n",
    "\n",
    "    # Scale the selected columns and update the DataFrame\n",
    "    df[selected_columns] = scaler.fit_transform(df[selected_columns])\n",
    "\n",
    "    #df.to_csv(\"D:\\\\1. Python\\\\1. NBA Script\\\\2025\\\\Gathering_Data\\\\Whole_Statistic\\\\df_orig.csv\", index=False)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "059f50fb",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alexx\\AppData\\Local\\Temp\\ipykernel_20208\\1084867453.py:1: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df.groupby([\"home\"]).apply(lambda x: x[x[\"won\"] == 1].shape[0] / x.shape[0])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "home\n",
       "0.0    0.432518\n",
       "1.0    0.567482\n",
       "dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "df.groupby([\"home\"]).apply(lambda x: x[x[\"won\"] == 1].shape[0] / x.shape[0])\n",
    "\n",
    "#print(df_rolling.head(60).to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "465c0fee",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alexx\\AppData\\Local\\Temp\\ipykernel_20208\\1983825367.py:18: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_rolling = df_rolling.groupby([\"team\", \"season\"], group_keys=False).apply(find_team_averages)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "####################################################################################################\n",
    "# CALCULATE THE AVERAGE FOR THE PREVIOUS SEASONS WITH THE ROLLING WINDOW OF 7 FOR LEARNING THE MODEL #\n",
    "####################################################################################################\n",
    "\n",
    "# Filter out the games from the current season\n",
    "df_rolling = df[list(selected_columns) + [\"won\", \"team\", \"season\"]]\n",
    "#df_rolling = df_rolling[df_rolling['season'] != current_season].copy()\n",
    "\n",
    "#print(df_rolling.columns)\n",
    "def find_team_averages(team):\n",
    "    numeric_columns = team.select_dtypes(include=[np.number])  # Select only numeric columns\n",
    "    rolling = numeric_columns.rolling(ROLLING_WINDOW_SIZE, min_periods=1).mean()  # Calculate rolling mean\n",
    "    #rolling[['team', 'season']] = team[['team', 'season']]  # Retain 'team' and 'season' columns in the result\n",
    "    return rolling\n",
    "\n",
    "# Apply rolling average\n",
    "df_rolling.reset_index(drop=True, inplace=True)\n",
    "df_rolling = df_rolling.groupby([\"team\", \"season\"], group_keys=False).apply(find_team_averages)\n",
    "\n",
    "\n",
    "# Renaming columns with _7 suffix for numeric columns only\n",
    "rolling_cols = {col: f\"{col}_7\" for col in df_rolling.columns if col not in ['team', 'season']} #, 'season','season_rolling','season_original','target']}\n",
    "\n",
    "\n",
    "# Rename the columns\n",
    "df_rolling.rename(columns=rolling_cols, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bb881205",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             fg       fga       fg%        3p       3pa       3p%        ft  \\\n",
      "0      0.391304  0.323529  0.656339  0.275862  0.348485  0.351544  0.272727   \n",
      "1      0.500000  0.338235  0.736429  0.344828  0.303030  0.495249  0.409091   \n",
      "2      0.369565  0.338235  0.631584  0.275862  0.287879  0.413302  0.386364   \n",
      "3      0.391304  0.411765  0.000208  0.241379  0.378788  0.286223  0.295455   \n",
      "4      0.391304  0.441176  0.598091  0.241379  0.257576  0.395487  0.386364   \n",
      "...         ...       ...       ...       ...       ...       ...       ...   \n",
      "24683  0.347826  0.382353  0.000189  0.413793  0.621212  0.000317  0.181818   \n",
      "24684  0.413043  0.455882  0.000205  0.379310  0.530303  0.000335  0.250000   \n",
      "24685  0.326087  0.397059  0.000166  0.344828  0.439394  0.000360  0.568182   \n",
      "24686  0.347826  0.455882  0.000157  0.344828  0.560606  0.000290  0.204545   \n",
      "24687  0.586957  0.441176  0.000341  0.551724  0.500000  0.000513  0.250000   \n",
      "\n",
      "            fta       orb       drb  ...  ast%_max_opp_7  stl%_max_opp_7  \\\n",
      "0      0.234375  0.241379  0.386364  ...        0.261468        0.032000   \n",
      "1      0.406250  0.241379  0.363636  ...        0.250573        0.043500   \n",
      "2      0.343750  0.275862  0.477273  ...        0.280963        0.047333   \n",
      "3      0.218750  0.310345  0.522727  ...        0.293578        0.043750   \n",
      "4      0.343750  0.551724  0.431818  ...        0.256422        0.044600   \n",
      "...         ...       ...       ...  ...             ...             ...   \n",
      "24683  0.156250  0.379310  0.113636  ...        0.319381        0.075250   \n",
      "24684  0.234375  0.448276  0.477273  ...        0.309346        0.087625   \n",
      "24685  0.468750  0.448276  0.409091  ...        0.326405        0.087000   \n",
      "24686  0.187500  0.275862  0.386364  ...        0.278526        0.070750   \n",
      "24687  0.265625  0.206897  0.477273  ...        0.272936        0.074125   \n",
      "\n",
      "       blk%_max_opp_7  tov%_max_opp_7  usg%_max_opp_7  ortg_max_opp_7  \\\n",
      "0            0.047000        0.300839        0.020513        0.203791   \n",
      "1            0.042500        0.325996        0.105769        0.329384   \n",
      "2            0.064667        0.341370        0.089316        0.262243   \n",
      "3            0.070750        0.300314        0.085897        0.446682   \n",
      "4            0.074600        0.338574        0.100769        0.408531   \n",
      "...               ...             ...             ...             ...   \n",
      "24683        0.101125        0.410115        0.112340        0.431280   \n",
      "24684        0.103625        0.403826        0.103365        0.440758   \n",
      "24685        0.108375        0.425839        0.107372        0.446090   \n",
      "24686        0.115375        0.439072        0.107692        0.441943   \n",
      "24687        0.117750        0.424921        0.114263        0.437204   \n",
      "\n",
      "       drtg_max_opp_7  total_opp_7  home_opp_7  season  \n",
      "0            0.290323     0.375000    0.000000  2016.0  \n",
      "1            0.354839     0.352679    0.500000  2016.0  \n",
      "2            0.329749     0.324405    0.333333  2016.0  \n",
      "3            0.344086     0.305804    0.500000  2016.0  \n",
      "4            0.350538     0.294643    0.600000  2016.0  \n",
      "...               ...          ...         ...     ...  \n",
      "24683        0.415323     0.507812    0.250000  2025.0  \n",
      "24684        0.424731     0.498884    0.375000  2025.0  \n",
      "24685        0.393817     0.507812    0.250000  2025.0  \n",
      "24686        0.368280     0.459821    0.375000  2025.0  \n",
      "24687        0.375000     0.463170    0.500000  2025.0  \n",
      "\n",
      "[24688 rows x 267 columns]\n",
      "815      2\n",
      "1729     2\n",
      "2525     2\n",
      "3306     2\n",
      "4074     2\n",
      "4921     2\n",
      "5752     2\n",
      "6610     2\n",
      "7388     2\n",
      "8280     2\n",
      "9115     2\n",
      "9937     2\n",
      "10777    2\n",
      "11596    2\n",
      "12410    2\n",
      "13278    2\n",
      "14137    2\n",
      "14943    2\n",
      "15734    2\n",
      "16531    2\n",
      "17359    2\n",
      "18149    2\n",
      "18987    2\n",
      "19808    2\n",
      "20627    2\n",
      "21405    2\n",
      "22215    2\n",
      "23067    2\n",
      "23888    2\n",
      "24687    2\n",
      "Name: target, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "df = df.reset_index(drop=True)\n",
    "df_rolling = df_rolling.reset_index(drop=True)\n",
    "\n",
    "df = pd.concat([df, df_rolling], axis=1)\n",
    "\n",
    "#df.to_csv(\"D:\\\\1. Python\\\\1. NBA Script\\\\2025\\\\Gathering_Data\\\\Whole_Statistic\\\\df_pd.concat.csv\", index=False)\n",
    "\n",
    "\n",
    "df = df.dropna()\n",
    "\n",
    "print(df)\n",
    "\n",
    "target_2_rows = df[df['target'] == 2]['target']\n",
    "print(target_2_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e288608d",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "815      2\n",
      "1729     2\n",
      "2525     2\n",
      "3306     2\n",
      "4074     2\n",
      "4921     2\n",
      "5752     2\n",
      "6610     2\n",
      "7388     2\n",
      "8280     2\n",
      "9115     2\n",
      "9937     2\n",
      "10777    2\n",
      "11596    2\n",
      "12410    2\n",
      "13278    2\n",
      "14137    2\n",
      "14943    2\n",
      "15734    2\n",
      "16531    2\n",
      "17359    2\n",
      "18149    2\n",
      "18987    2\n",
      "19808    2\n",
      "20627    2\n",
      "21405    2\n",
      "22215    2\n",
      "23067    2\n",
      "23888    2\n",
      "24687    2\n",
      "Name: target, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alexx\\AppData\\Local\\Temp\\ipykernel_20208\\2232954841.py:8: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  return df.groupby(\"team\", group_keys=False).apply(lambda x: shift_col(x, col_name))\n",
      "C:\\Users\\alexx\\AppData\\Local\\Temp\\ipykernel_20208\\2232954841.py:8: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  return df.groupby(\"team\", group_keys=False).apply(lambda x: shift_col(x, col_name))\n",
      "C:\\Users\\alexx\\AppData\\Local\\Temp\\ipykernel_20208\\2232954841.py:8: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  return df.groupby(\"team\", group_keys=False).apply(lambda x: shift_col(x, col_name))\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "def shift_col(team, col_name):\n",
    "    next_col = team[col_name].shift(-1)\n",
    "    return next_col\n",
    "\n",
    "def add_col(df, col_name):\n",
    "    # Ensure the 'team' column is not part of the index and is correctly formatted\n",
    "    if 'team' in df.columns:\n",
    "        return df.groupby(\"team\", group_keys=False).apply(lambda x: shift_col(x, col_name))\n",
    "    else:\n",
    "        raise KeyError(\"The 'team' column is missing or not properly formatted in the DataFrame.\")\n",
    "\n",
    "# Ensure the 'team' column exists and is not part of the index\n",
    "if 'team' not in df.columns:\n",
    "    print(\"The 'team' column is missing. Ensure the column is present in your DataFrame.\")\n",
    "\n",
    "# Reset the index to avoid potential issues with multi-indexing\n",
    "df = df.reset_index(drop=True)\n",
    "\n",
    "# Add shifted columns for \"home\", \"team_opp\", and \"date\"\n",
    "df[\"home_next\"] = add_col(df, \"home\")\n",
    "df[\"team_opp_next\"] = add_col(df, \"team_opp\")\n",
    "df[\"date_next\"] = add_col(df, \"date\")\n",
    "\n",
    "# Drop rows where any of the next columns contain NaN values (optional)\n",
    "#df = df.dropna(subset=[\"home_next\", \"team_opp_next\", \"date_next\"])\n",
    "\n",
    "# Optionally, save the DataFrame to a CSV file\n",
    "#df.to_csv(\"D:\\\\1. Python\\\\1. NBA Script\\\\2025\\\\Gathering_Data\\\\Whole_Statistic\\\\df_dropna_target_2.csv\", index=False)\n",
    "#df.to_csv(\"D:\\\\1. Python\\\\1. NBA Script\\\\2025\\\\Gathering_Data\\\\Whole_Statistic\\\\df.csv\", index=False)\n",
    "\n",
    "\n",
    "# Display the first few rows to check the output\n",
    "#print(df.head())\n",
    "\n",
    "target_2_rows = df[df['target'] == 2]['target']\n",
    "print(target_2_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b841905b",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEN\n",
      "LAC\n",
      "2025-05-03\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "for _, game in games_df.iterrows():\n",
    "    home_team = game['home_team']\n",
    "    away_team = game['away_team']\n",
    "    game_day = game['game_date']\n",
    "    \n",
    "    print(home_team)\n",
    "    print(away_team)\n",
    "    print(game_day)\n",
    "\n",
    "\n",
    "    last_home_team_index = df.loc[df['team'] == home_team].iloc[::-1].index[0]\n",
    "    \n",
    "    df.loc[last_home_team_index, 'team_opp_next'] = away_team\n",
    "    df.loc[last_home_team_index, 'home_next'] = 1\n",
    "    df.loc[last_home_team_index, 'date_next'] = game_day\n",
    "    \n",
    "\n",
    "    last_away_team_index = df.loc[df['team'] == away_team].iloc[::-1].index[0]\n",
    "    \n",
    "    df.loc[last_away_team_index, 'team_opp_next'] = home_team\n",
    "    df.loc[last_away_team_index, 'home_next'] = 0\n",
    "    df.loc[last_away_team_index, 'date_next'] = game_day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e5325b01",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full DataFrame Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 24856 entries, 0 to 24855\n",
      "Columns: 402 entries, fg_x to team_y\n",
      "dtypes: bool(1), float64(392), int64(2), object(7)\n",
      "memory usage: 76.1+ MB\n",
      "None\n",
      "\n",
      "First few rows of the merged DataFrame:\n",
      "       fg_x     fga_x     fg%_x      3p_x     3pa_x     3p%_x      ft_x  \\\n",
      "0  0.391304  0.323529  0.656339  0.275862  0.348485  0.351544  0.272727   \n",
      "1  0.500000  0.338235  0.736429  0.344828  0.303030  0.495249  0.409091   \n",
      "2  0.369565  0.338235  0.631584  0.275862  0.287879  0.413302  0.386364   \n",
      "3  0.391304  0.411765  0.000208  0.241379  0.378788  0.286223  0.295455   \n",
      "4  0.391304  0.441176  0.598091  0.241379  0.257576  0.395487  0.386364   \n",
      "\n",
      "      fta_x     orb_x     drb_x  ...  stl%_max_opp_y  blk%_max_opp_y  \\\n",
      "0  0.234375  0.241379  0.386364  ...           0.034           0.068   \n",
      "1  0.406250  0.241379  0.363636  ...           0.061           0.079   \n",
      "2  0.343750  0.275862  0.477273  ...           0.047           0.045   \n",
      "3  0.218750  0.310345  0.522727  ...           0.047           0.053   \n",
      "4  0.343750  0.551724  0.431818  ...           0.070           0.071   \n",
      "\n",
      "   tov%_max_opp_y  usg%_max_opp_y  ortg_max_opp_y  drtg_max_opp_y  \\\n",
      "0        0.475891        0.134615        0.241706        0.645161   \n",
      "1        0.475891        0.155128        0.682464        0.365591   \n",
      "2        0.197065        0.055128        0.161137        0.301075   \n",
      "3        0.408805        0.114103        0.298578        0.483871   \n",
      "4        0.737945        0.114103        0.417062        0.397849   \n",
      "\n",
      "   total_opp_y  home_opp_y  team_opp_next_y  team_y  \n",
      "0     0.294643         1.0              ATL     NYK  \n",
      "1     0.357143         1.0              ATL     CHO  \n",
      "2     0.294643         1.0              ATL     CHO  \n",
      "3     0.223214         0.0              ATL     MIA  \n",
      "4     0.348214         0.0              ATL     BRK  \n",
      "\n",
      "[5 rows x 402 columns]\n",
      "Number of rows in 'full' DataFrame: 24856\n",
      "\n",
      "Rows where 'target' == 2:\n",
      "6659     2\n",
      "10863    2\n",
      "Name: target, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Merging DataFrames\n",
    "# Convert rolling_cols dictionary keys to a list and add other columns\n",
    "full = df.merge(df[list(rolling_cols.keys()) + [\"team_opp_next\", \"date_next\", \"team\"]], \n",
    "                left_on=[\"team\", \"date_next\"], \n",
    "                right_on=[\"team_opp_next\", \"date_next\"])\n",
    "\n",
    "\n",
    "# Save the merged DataFrame\n",
    "output_path = \"D:\\\\1. Python\\\\1. NBA Script\\\\2025\\\\Gathering_Data\\\\Whole_Statistic\\\\full_new.csv\"\n",
    "full.to_csv(output_path, index=False)\n",
    "#print(f\"Merged data saved to: {output_path}\")\n",
    "\n",
    "# Display basic info and first few rows of the merged DataFrame\n",
    "print(\"Full DataFrame Info:\")\n",
    "print(full.info())\n",
    "print(\"\\nFirst few rows of the merged DataFrame:\")\n",
    "print(full.head())\n",
    "\n",
    "# Print number of rows in the merged DataFrame\n",
    "num_rows = full.shape[0]\n",
    "print(f\"Number of rows in 'full' DataFrame: {num_rows}\")\n",
    "\n",
    "# Extract and print rows with target == 2\n",
    "target_2_rows = full[full['target'] == 2]['target']\n",
    "print(\"\\nRows where 'target' == 2:\")\n",
    "print(target_2_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2d1b8313",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      team_x team_opp_next_x team_y team_opp_next_y   date_next  home_next\n",
      "6659     DEN             LAC    LAC             DEN  2025-05-03        1.0\n",
      "10863    LAC             DEN    DEN             LAC  2025-05-03        0.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "mask = full['date_next'] == game_day\n",
    "filtered_df = full.loc[mask, ['team_x', 'team_opp_next_x', 'team_y', 'team_opp_next_y', 'date_next', 'home_next']]\n",
    "\n",
    "print(filtered_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bc68d9d6",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "removed_columns = list(full.columns[full.dtypes == \"object\"]) + removed_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "00509431",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['fg_x', 'fga_x', 'fg%_x', '3p_x', '3pa_x', '3p%_x', 'ft_x', 'fta_x',\n",
       "       'orb_x', 'drb_x',\n",
       "       ...\n",
       "       'trb%_max_opp_y', 'ast%_max_opp_y', 'stl%_max_opp_y', 'blk%_max_opp_y',\n",
       "       'tov%_max_opp_y', 'usg%_max_opp_y', 'ortg_max_opp_y', 'drtg_max_opp_y',\n",
       "       'total_opp_y', 'home_opp_y'],\n",
       "      dtype='object', length=391)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "selected_columns = full.columns[~full.columns.isin(removed_columns)]\n",
    "selected_features = selected_columns.unique()\n",
    "\n",
    "selected_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cd0b1dd8",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           fg_x     fga_x     fg%_x      3p_x     3pa_x     3p%_x      ft_x  \\\n",
      "6659   0.543478  0.352941  0.000360  0.379310  0.348485  0.000483  0.136364   \n",
      "10863  0.521739  0.382353  0.000325  0.413793  0.530303  0.000366  0.295455   \n",
      "\n",
      "          fta_x     orb_x     drb_x  ...  stl%_max_opp_y  blk%_max_opp_y  \\\n",
      "6659   0.140625  0.344828  0.295455  ...           0.044           0.095   \n",
      "10863  0.234375  0.310345  0.227273  ...           0.031           0.094   \n",
      "\n",
      "       tov%_max_opp_y  usg%_max_opp_y  ortg_max_opp_y  drtg_max_opp_y  \\\n",
      "6659         1.000000        0.107692        0.454976        0.602151   \n",
      "10863        0.112159        0.105128        0.312796        0.548387   \n",
      "\n",
      "       total_opp_y  home_opp_y  team_opp_next_y  team_y  \n",
      "6659      0.366071         0.0              DEN     LAC  \n",
      "10863     0.419643         1.0              LAC     DEN  \n",
      "\n",
      "[2 rows x 402 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "full_train = full[full[\"target\"] != 2]\n",
    "full_pred = full[full[\"target\"] == 2]\n",
    "\n",
    "print(full_pred)\n",
    "\n",
    "X = full_train[selected_features].values\n",
    "y = full_train[\"target\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "93bd05fb",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "378e3eb3",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Define the parameter grid\n",
    "param_grid = {\n",
    "    'num_leaves': [10, 20, 30],\n",
    "    'learning_rate': [0.01, 0.05, 0.1],\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'min_child_weight': [1, 5, 10]\n",
    "}\n",
    "\n",
    "# Create a LightGBM classifier\n",
    "base_estimator = lgb.LGBMClassifier(objective='binary',\n",
    "                                     metric='auc',\n",
    "                                     boosting_type='gbdt',\n",
    "                                     verbosity=-1,\n",
    "                                     random_state=42)\n",
    "\n",
    "# Initialize GridSearchCV\n",
    "grid_search = GridSearchCV(estimator=base_estimator,\n",
    "                           param_grid=param_grid,\n",
    "                           scoring='roc_auc',\n",
    "                           cv=5,\n",
    "                           verbose=1,\n",
    "                           n_jobs=-1)\n",
    "\n",
    "# Perform grid search\n",
    "#grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Print the best parameters\n",
    "#print(\"Best parameters found:\", grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0943262e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#Best parameters found: {'learning_rate': 0.1, 'max_depth': 7, 'min_child_weight': 5, 'num_leaves': 10}\n",
    "\n",
    "params = {\n",
    "    'objective': 'binary',\n",
    "    'metric': 'auc',\n",
    "    'num_leaves': 10,\n",
    "    'learning_rate': 0.1,\n",
    "    'feature_fraction': 0.9,\n",
    "    'bagging_fraction': 0.9,\n",
    "    'bagging_freq': 10,\n",
    "    'boosting_type': 'gbdt',\n",
    "    'verbosity': -1,\n",
    "    'random_state': 42,\n",
    "    'lambda_l1': 0.5,\n",
    "    'lambda_l2': 0.5,\n",
    "    'max_depth': 7,\n",
    "    'min_child_weight': 5\n",
    "}\n",
    "\n",
    "model = lgb.LGBMClassifier(**params)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3c6cf9ee",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 61.05%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\1. Python\\Python Installation x64\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Train the model using X_train and y_train\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict the target values for the test set X_test\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Check the accuracy of the model using the test set\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy: {:.2f}%\".format(accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "468151eb",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drtg_7: 27\n",
      "home_next: 27\n",
      "ortg_7: 21\n",
      "pts_max_7: 15\n",
      "pts_opp_7: 14\n",
      "ortg_y: 14\n",
      "drtg_y: 13\n",
      "pts_max_y: 12\n",
      "ortg_max_y: 11\n",
      "ast_max_7: 10\n",
      "3par_max_y: 10\n",
      "ft_max_7: 9\n",
      "fta_max_7: 9\n",
      "drb_max_7: 9\n",
      "blk_opp_7: 9\n",
      "pts_opp_y: 9\n",
      "drb%_7: 8\n",
      "ortg_max_7: 8\n",
      "blk%_opp_7: 8\n",
      "fg_max_y: 8\n",
      "ft_max_y: 8\n",
      "ast_7: 7\n",
      "tov%_7: 7\n",
      "stl%_max_7: 7\n",
      "usg%_max_7: 7\n",
      "3p%_opp_y: 7\n",
      "ftr_max_opp_y: 7\n",
      "blk%_x: 6\n",
      "trb_max_7: 6\n",
      "trb%_max_7: 6\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "importances = model.feature_importances_\n",
    "\n",
    "# create a dictionary to store feature importances with column names\n",
    "feat_importances = dict(zip(selected_columns, importances))\n",
    "\n",
    "# sort the dictionary by importance score in descending order\n",
    "sorted_feat_importances = sorted(feat_importances.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "\n",
    "# Print the sorted feature importances\n",
    "for feature, importance in sorted_feat_importances[:30]:\n",
    "    print(\"{}: {}\".format(feature, importance))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e6f9300b",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alexx\\AppData\\Local\\Temp\\ipykernel_20208\\1306744011.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  full_pred[\"proba\"] = model.predict_proba(full_pred[selected_features])[:,1]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "6659     0.575283\n",
       "10863    0.672856\n",
       "Name: proba, dtype: float64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "# predict on new data\n",
    "full_pred[\"proba\"] = model.predict_proba(full_pred[selected_features])[:,1]\n",
    "full_pred[\"proba\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ccbe991a",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6659    0.575283\n",
       "Name: proba, dtype: float64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "home_teams_prob = list(games_df['home_team'])\n",
    "away_teams_prob = list(games_df['away_team'])\n",
    "\n",
    "#print(home_teams_prob)\n",
    "#print(away_teams_prob)\n",
    "\n",
    "# Filter the rows where team_x is a home team\n",
    "full_pred_prob = full_pred['team_x'].isin(home_teams_prob)\n",
    "#print(full_pred_prob)\n",
    "\n",
    "#full_pred_prob = full_pred['team_x'].isin(home_teams_prob)\n",
    "full_pred[full_pred_prob]['proba']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1e3c6d7c",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     team_x team_y\n",
      "6659    DEN    LAC\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Filter rows where full_pred_prob is True\n",
    "\n",
    "team_x = full_pred.loc[full_pred_prob, 'team_x']\n",
    "team_y = full_pred.loc[full_pred_prob, 'team_y']\n",
    "#print(team_x)\n",
    "#print(team_y)\n",
    "\n",
    "team_pairs = pd.concat([team_x, team_y], axis=1)\n",
    "\n",
    "\n",
    "print(team_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7e60553b-a0b4-49ce-9186-81194a9ffef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests, pandas as pd, logging\n",
    "from requests.adapters import HTTPAdapter\n",
    "from urllib3.util.retry import Retry\n",
    "\n",
    "# full-name → 3-letter abbr\n",
    "full_to_abbrev = {\n",
    "    \"Atlanta Hawks\":\"ATL\",\"Boston Celtics\":\"BOS\",\"Brooklyn Nets\":\"BRK\",\n",
    "    \"Charlotte Hornets\":\"CHA\",\"Chicago Bulls\":\"CHI\",\"Cleveland Cavaliers\":\"CLE\",\n",
    "    \"Dallas Mavericks\":\"DAL\",\"Denver Nuggets\":\"DEN\",\"Detroit Pistons\":\"DET\",\n",
    "    \"Golden State Warriors\":\"GSW\",\"Houston Rockets\":\"HOU\",\"Indiana Pacers\":\"IND\",\n",
    "    \"LA Clippers\":\"LAC\",\"Los Angeles Clippers\":\"LAC\",\"Los Angeles Lakers\":\"LAL\",\n",
    "    \"Memphis Grizzlies\":\"MEM\",\"Miami Heat\":\"MIA\",\"Milwaukee Bucks\":\"MIL\",\n",
    "    \"Minnesota Timberwolves\":\"MIN\",\"New Orleans Pelicans\":\"NOP\",\n",
    "    \"New York Knicks\":\"NYK\",\"Oklahoma City Thunder\":\"OKC\",\"Orlando Magic\":\"ORL\",\n",
    "    \"Philadelphia 76ers\":\"PHI\",\"Phoenix Suns\":\"PHX\",\"Portland Trail Blazers\":\"POR\",\n",
    "    \"Sacramento Kings\":\"SAC\",\"San Antonio Spurs\":\"SAS\",\"Toronto Raptors\":\"TOR\",\n",
    "    \"Utah Jazz\":\"UTA\",\"Washington Wizards\":\"WAS\"\n",
    "}\n",
    "\n",
    "def get_session():\n",
    "    s = requests.Session()\n",
    "    retries = Retry(total=3, backoff_factor=0.5,\n",
    "                    status_forcelist=[429,500,502,503,504])\n",
    "    s.mount(\"https://\", HTTPAdapter(max_retries=retries))\n",
    "    return s\n",
    "\n",
    "def fetch_odds(games_df: pd.DataFrame, api_key: str,\n",
    "               preferred: list=None) -> pd.DataFrame:\n",
    "    sess = get_session()\n",
    "    r = sess.get(\n",
    "      \"https://api.the-odds-api.com/v4/sports/basketball_nba/odds\",\n",
    "      params={\"apiKey\":api_key,\"regions\":\"us\",\"markets\":\"h2h\",\"oddsFormat\":\"american\"},\n",
    "      timeout=10\n",
    "    )\n",
    "    r.raise_for_status()\n",
    "    data = r.json()\n",
    "\n",
    "    # build lookup: (home,away) → (priceH,priceA)\n",
    "    lookup = {}\n",
    "    for ev in data:\n",
    "        h_abbr = full_to_abbrev.get(ev[\"home_team\"])\n",
    "        a_abbr = full_to_abbrev.get(ev[\"away_team\"])\n",
    "        if not h_abbr or not a_abbr or not ev.get(\"bookmakers\"):\n",
    "            continue\n",
    "\n",
    "        # pick bookmaker\n",
    "        bms = ev[\"bookmakers\"]\n",
    "        bm = None\n",
    "        if preferred:\n",
    "            for key in preferred:\n",
    "                bm = next((b for b in bms if b[\"key\"]==key), None)\n",
    "                if bm: break\n",
    "        if bm is None: bm = bms[0]\n",
    "\n",
    "        mkt = next((m for m in bm[\"markets\"] if m[\"key\"]==\"h2h\"), None)\n",
    "        if not mkt: continue\n",
    "\n",
    "        prices = {}\n",
    "        for out in mkt[\"outcomes\"]:\n",
    "            abbr = full_to_abbrev.get(out[\"name\"])\n",
    "            if abbr:\n",
    "                prices[abbr] = out[\"price\"]\n",
    "\n",
    "        lookup[(h_abbr, a_abbr)] = (prices.get(h_abbr), prices.get(a_abbr))\n",
    "\n",
    "    rows = []\n",
    "    for _, gm in games_df.iterrows():\n",
    "        h,a = gm.home_team, gm.away_team\n",
    "        o1,o2 = lookup.get((h,a),(None,None))\n",
    "        if o1 is None or o2 is None:\n",
    "            logging.warning(f\"No odds found for {h} vs {a}\")\n",
    "        rows.append({\"home_team\":h,\"away_team\":a,\"odds 1\":o1,\"odds 2\":o2})\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "def impute_prob(ml):\n",
    "    if ml is None: return None\n",
    "    ml = int(ml)\n",
    "    return abs(ml)/(abs(ml)+100) if ml<0 else 100/(ml+100)\n",
    "\n",
    "def merge_with_odds(preds: pd.DataFrame, odds: pd.DataFrame) -> pd.DataFrame:\n",
    "    df = preds.merge(odds, on=[\"home_team\",\"away_team\"], how=\"left\")\n",
    "    tmp = preds.drop(columns=[c for c in [\"odds 1\",\"odds 2\"] if c in preds], errors=\"ignore\")\n",
    "    df = tmp.merge(odds, on=[\"home_team\",\"away_team\"], how=\"left\")\n",
    "    df[\"imp_prob_home\"] = df[\"odds 1\"].apply(impute_prob)\n",
    "    df[\"imp_prob_away\"] = df[\"odds 2\"].apply(impute_prob)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "974b319c-b24d-4859-bffe-bc6de3678b90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  home_team away_team  home_team_prob  result        date  odds 1  odds 2  \\\n",
      "0       DEN       LAC        0.575283       0  2025-05-03    -118    -102   \n",
      "\n",
      "   imp_prob_home  imp_prob_away  value_home  value_away  \n",
      "0       0.541284        0.50495    0.033998   -0.080233  \n"
     ]
    }
   ],
   "source": [
    "# assume you already have `home_team_preds` DataFrame in this notebook\n",
    "\n",
    "\n",
    "\n",
    "# 1) Re-create your home_team_preds DataFrame\n",
    "home_team_preds_ml = (\n",
    "    full_pred\n",
    "      .loc[full_pred_prob, ['team_x','team_y','proba']]\n",
    "      .rename(columns={\n",
    "          'team_x': 'home_team',\n",
    "          'team_y': 'away_team',\n",
    "          'proba':  'home_team_prob'\n",
    "      })\n",
    "      .assign(result=0, date=game_day)\n",
    ")\n",
    "\n",
    "API_KEY   = \"8e9d506f8573b01023028cef1bf645b5\"\n",
    "odds_df    = fetch_odds(home_team_preds_ml, API_KEY, preferred=[\"draftkings\",\"fanduel\"])\n",
    "\n",
    "# inspect to confirm you have 'odds 1' & 'odds 2' columns:\n",
    "# print(odds_df.head())\n",
    "# print(\"Columns:\", odds_df.columns.tolist())\n",
    "\n",
    "final_df = merge_with_odds(home_team_preds_ml, odds_df)\n",
    "#print(final_df.head())\n",
    "\n",
    "# save out:\n",
    "# final_df.to_csv(\n",
    "#     \"D:/1. Python/1. NBA Script/2025/LightGBM/1. 2025_Prediction/predictions_with_odds.csv\",\n",
    "#     index=False\n",
    "# )\n",
    "\n",
    "final_df[\"value_home\"] = final_df[\"home_team_prob\"] - final_df[\"imp_prob_home\"]\n",
    "final_df[\"value_away\"] = (1 - final_df[\"home_team_prob\"]) - final_df[\"imp_prob_away\"]\n",
    "print(final_df.sort_values(\"value_home\", ascending=False).head())\n",
    "\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# plt.scatter(final_df[\"imp_prob_home\"], final_df[\"home_team_prob\"])\n",
    "# plt.plot([0,1],[0,1], linestyle=\"--\")\n",
    "# plt.xlabel(\"Market Implied Probability\")\n",
    "# plt.ylabel(\"Model Predicted Probability\")\n",
    "# plt.title(\"Model vs Market Comparison\")\n",
    "# plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c3482332-5edc-47f3-a174-bf68564882b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "home_team away_team  home_team_prob  odds 1  odds 2  result       date\n",
      "      DEN       LAC        0.575283    1.85    1.98       0 2025-05-03\n"
     ]
    }
   ],
   "source": [
    "# 1) Build your predictions DataFrame (no placeholder zeros)\n",
    "home_team_preds = (\n",
    "    full_pred\n",
    "    .loc[full_pred_prob, ['team_x', 'team_y', 'proba']]\n",
    "    .rename(columns={\n",
    "        'team_x': 'home_team',\n",
    "        'team_y': 'away_team',\n",
    "        'proba':  'home_team_prob'\n",
    "    })\n",
    "    .assign(result=0, date=game_day)\n",
    ")\n",
    "\n",
    "# 2) Merge in the actual American odds (from odds_df)\n",
    "home_team_preds = home_team_preds.merge(\n",
    "    odds_df[['home_team', 'away_team', 'odds 1', 'odds 2']],\n",
    "    on=['home_team', 'away_team'],\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# 3) Convert American odds to decimal odds\n",
    "def am_to_dec(ml):\n",
    "    if pd.isna(ml):\n",
    "        return None\n",
    "    ml = int(ml)\n",
    "    return (ml/100 + 1) if ml > 0 else (100/abs(ml) + 1)\n",
    "\n",
    "home_team_preds['odds 1'] = home_team_preds['odds 1'].apply(am_to_dec)\n",
    "home_team_preds['odds 2'] = home_team_preds['odds 2'].apply(am_to_dec)\n",
    "\n",
    "# Round to two decimal places\n",
    "home_team_preds['odds 1'] = home_team_preds['odds 1'].apply(lambda x: round(x, 2) if pd.notnull(x) else x)\n",
    "home_team_preds['odds 2'] = home_team_preds['odds 2'].apply(lambda x: round(x, 2) if pd.notnull(x) else x)\n",
    "\n",
    "# 4) Display in the exact format requested\n",
    "cols = ['home_team', 'away_team', 'home_team_prob', 'odds 1', 'odds 2', 'result', 'date']\n",
    "print(home_team_preds[cols].to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b97dbe80-0e2d-4840-a00c-8f2189501f0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "💾 Saved predictions to D:\\1. Python\\1. NBA Script\\2025\\LightGBM\\1. 2025_Prediction\\nba_games_predict_2025-05-03.csv\n"
     ]
    }
   ],
   "source": [
    "# pick the exact column order\n",
    "cols = [\n",
    "    \"home_team\",\n",
    "    \"away_team\",\n",
    "    \"home_team_prob\",\n",
    "    \"result\",    \n",
    "    \"odds 1\",\n",
    "    \"odds 2\",\n",
    "    \"date\"\n",
    "]\n",
    "\n",
    "# subset/reorder\n",
    "to_save = home_team_preds[cols]\n",
    "\n",
    "# now save it\n",
    "file_name = f\"nba_games_predict_{today}.csv\"\n",
    "full_path = os.path.join(directory_path, file_name)\n",
    "os.makedirs(directory_path, exist_ok=True)\n",
    "\n",
    "if os.path.exists(full_path):\n",
    "    print(f\"✅ File already exists: {full_path}\")\n",
    "else:\n",
    "    to_save.to_csv(full_path, index=False)\n",
    "    print(f\"💾 Saved predictions to {full_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "88f4c834",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\1. Python\\1. NBA Script\\2025\\LightGBM\\1. 2025_Prediction\n",
      "Files in source but not in destination:\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Open folder using subprocess on Windows\n",
    "if os.name == 'nt':\n",
    "    subprocess.Popen(f'explorer {directory_path}')\n",
    "print(directory_path)\n",
    "file_path = directory_path + \"/\" + file_name\n",
    "\n",
    "src_files = set(os.listdir(directory_path))\n",
    "dst_files = set(os.listdir(dst_dir))\n",
    "\n",
    "diff = src_files - dst_files\n",
    "diff_ = {file for file in diff if not file.startswith('.')}\n",
    "\n",
    "print('Files in source but not in destination:')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "48553c20",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No files to copy\n"
     ]
    }
   ],
   "source": [
    "if diff_:\n",
    "    for file_name in diff_:\n",
    "        file_to_copy = os.path.join(directory_path, file_name)\n",
    "        shutil.copy2(file_to_copy, dst_dir)\n",
    "        print(f\"Copied {file_name} to {dst_dir}\")\n",
    "else:\n",
    "    print('No files to copy')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94b4b992-be86-40b2-9a01-78e6de2d8ea9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "encoding": "# coding: utf-8",
   "executable": "/usr/bin/env python",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
