{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "45c94199-6dc1-42a8-9a00-1b55e7e1ed0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################################################################################################################\n",
    "# COLLECT DATA FROM PREVIOUS GAME DAY AND ADD THEM TO GENERAL DATASET#\n",
    "\n",
    "# Script 1 of 4\n",
    "# This script collects and processes data for the previous game day.\n",
    "# Ensure to run this script before executing `_2. 03012025_get_data_next_game_day.ipynb`.\n",
    "#########################################################################################################################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1b8b0b01-9ec7-4111-ad25-9f8d9da3cf6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the current season\n",
    "current_season = 2025"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0f361f87-eee2-4bf6-83e7-159389ac5db8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import shutil\n",
    "from io import StringIO\n",
    "import numpy as np\n",
    "\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "import logging\n",
    "\n",
    "import time\n",
    "import calendar\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By  # Corrected import\n",
    "from selenium.webdriver.chrome.service import Service  # Corrected import\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.common.exceptions import TimeoutException, WebDriverException\n",
    "\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d28b8089-ffcb-43a6-abfa-d54633ac213e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Today's date: Tue, Jan 21, 2025\n"
     ]
    }
   ],
   "source": [
    "today = datetime.now() - timedelta(days=0)\n",
    "today_str = today.strftime(\"%a, %b \") + str(int(today.strftime(\"%d\"))) + today.strftime(\", %Y\")\n",
    "today_date = datetime.strptime(today_str, \"%a, %b %d, %Y\")\n",
    "today_str_format = today_date.strftime(\"%Y-%m-%d\")\n",
    "\n",
    "yesterday = datetime.now() - timedelta(days=1)\n",
    "\n",
    "print(f\"Today's date: {today_str}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c6ccf8d3-3971-4cb7-a092-2c7da15fe107",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directories\n",
    "DATA_DIR = os.path.join(\"D:\\\\\", \"1. Python\", \"1. NBA Script\", \"2025\", \"Gathering_Data\")\n",
    "\n",
    "STAT_DIR = os.path.join(DATA_DIR, \"Whole_Statistic\")\n",
    "STANDINGS_DIR = os.path.join(DATA_DIR,\"data\", f\"{current_season}_standings\")\n",
    "SCORES_DIR = os.path.join(DATA_DIR,\"data\", f\"{current_season}_scores\")\n",
    "\n",
    "DST_DIR = os.path.join(\"D:\\\\\", \"_Laufwerk C\", \"11. Sorare\", \"NBA\",\"2025\", \"Gathering_Data\", \"Whole_Statistic\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0c863419-5526-4d80-a9f1-6acdfcc278f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to the manually downloaded ChromeDriver\n",
    "chromedriver_path = r\"D:\\1. Python\\3. chromedriver-win64\\chromedriver-win64\\chromedriver.exe\"  # Replace with your actual path\n",
    "chrome_options = Options()\n",
    "chrome_options.add_argument(\"--headless\")  # Run in headless mode (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a7466275-68db-4dab-91fb-f75f24ef469c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get today's date\n",
    "# Determine the current and next month/year\n",
    "\n",
    "if today.day == 1:\n",
    "    current_month = today.month - 1\n",
    "    \n",
    "    if current_month == 0:\n",
    "        current_month = 12\n",
    "        current_year = today.year - 1\n",
    "        last_month = 12\n",
    "        last_month_name = calendar.month_name[last_month].lower()\n",
    "    else:\n",
    "        current_year = today.year\n",
    "        last_month = current_month# - 1\n",
    "        last_month_name = calendar.month_name[last_month].lower()\n",
    "        print(last_month)\n",
    "else:\n",
    "    current_month = today.month\n",
    "    current_year = today.year\n",
    "    last_month = None  # Not used in this case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "92482aca-2e78-46dd-89d0-667607a1c89d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure logging\n",
    "chrome_options.add_argument(\"--disable-ipv6\")\n",
    "\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "def get_current_year_and_month():\n",
    "    \"\"\"\n",
    "    Returns the current year and month.\n",
    "    \"\"\"\n",
    "    #today = datetime.now()\n",
    "    return today.year, today.month\n",
    "\n",
    "def get_html(url, selector, sleep=5, retries=3, headless=True):\n",
    "    \"\"\"\n",
    "    Retrieves HTML content from a webpage using Selenium WebDriver.\n",
    "    \"\"\"\n",
    "    html = None\n",
    "    driver = None\n",
    "\n",
    "    try:\n",
    "        # WebDriver options\n",
    "        chrome_options = Options()\n",
    "        if headless:\n",
    "            chrome_options.add_argument(\"--headless\")\n",
    "\n",
    "####### Initialize WebDriver with Service #######\n",
    "        service = Service(chromedriver_path)\n",
    "        driver = webdriver.Chrome(service=service, options=chrome_options)\n",
    "#############################################################################\n",
    "        \n",
    "        for attempt in range(retries):\n",
    "            try:\n",
    "                driver.get(url)\n",
    "                time.sleep(sleep * (2 ** attempt))  # Exponential backoff\n",
    "                element = driver.find_element(By.CSS_SELECTOR, selector)\n",
    "                html = element.get_attribute(\"innerHTML\")\n",
    "                break\n",
    "            except TimeoutException:\n",
    "                logging.warning(f\"Attempt {attempt + 1}: Timeout error on {url}. Retrying...\")\n",
    "            except WebDriverException as e:\n",
    "                logging.error(f\"Webdriver error: {e}\")\n",
    "                break\n",
    "    finally:\n",
    "        if driver is not None:\n",
    "            driver.quit()\n",
    "\n",
    "    if html is None:\n",
    "        logging.error(f\"Failed to retrieve HTML content from {url} after {retries} attempts.\")\n",
    "\n",
    "    return html\n",
    "\n",
    "def scrape_season_for_month(season, month, month_name, standings_dir, get_html_function):\n",
    "    \"\"\"\n",
    "    Scrapes NBA games data for a specific month and season from basketball-reference.com.\n",
    "\n",
    "    Args:\n",
    "        season (int): The NBA season year.\n",
    "        month (int): The month number (1-12).\n",
    "        month_name (str): The name of the month.\n",
    "        standings_dir (str): Directory path to save the scraped data.\n",
    "        get_html_function (function): Function to get HTML content from a URL.\n",
    "    \"\"\"\n",
    "    if season < current_year or (season == current_year and month < current_month):\n",
    "        logging.warning(\"Invalid year or month already passed.\")\n",
    "        return\n",
    "\n",
    "    logging.info(f\"Scraping games for: {season}, {month_name.title()}\")\n",
    "    url = f\"https://www.basketball-reference.com/leagues/NBA_{season}_games.html\"\n",
    "    selector = \"#content .filter\"\n",
    "    html_content = get_html_function(url, selector)\n",
    "\n",
    "    if not html_content:\n",
    "        logging.error(f\"Failed to retrieve data from {url}.\")\n",
    "        return\n",
    "\n",
    "    soup = BeautifulSoup(html_content, 'html.parser')\n",
    "    links = soup.find_all(\"a\", href=re.compile(\"/leagues/NBA_[0-9]{4}_games-[a-z]+\\.html\"))\n",
    "    standings_pages = [f\"https://www.basketball-reference.com{l['href']}\" for l in links]\n",
    "\n",
    "    for url in standings_pages:\n",
    "        save_path = os.path.join(standings_dir, url.split(\"/\")[-1])\n",
    "        if os.path.exists(save_path):\n",
    "            logging.info(f\"Path already exists: {save_path}\")\n",
    "            continue\n",
    "\n",
    "        if month_name in save_path.lower():\n",
    "            html = get_html_function(url, \"#all_schedule\")\n",
    "            #print(html)\n",
    "            if html:\n",
    "                try:\n",
    "                    with open(save_path, \"w+\", encoding='utf-8') as f:\n",
    "                        f.write(html)\n",
    "                    logging.info(f\"Data for {month_name.title()} saved.\")\n",
    "                except Exception as e:\n",
    "                    logging.error(f\"Failed to save data for {month_name.title()}: {e}\")\n",
    "            else:\n",
    "                logging.error(f\"Failed to retrieve data for {month_name.title()} from {url}.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "419405f3-45e0-4b4b-a316-d792193c54df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_game(standings_file, scores_dir, get_html_function):\n",
    "    \"\"\"\n",
    "    Scrapes box scores for NBA games from the provided standings file.\n",
    "\n",
    "    Args:\n",
    "        standings_file (str): Path to the file containing the standings data.\n",
    "        scores_dir (str): Directory path to save the scraped box scores.\n",
    "        get_html_function (function): Function to get HTML content from a URL.\n",
    "    \"\"\"\n",
    "    # Calculate the date of yesterday\n",
    "    yesterday_date = yesterday.strftime(\"%Y%m%d\")  # Format: YYYYMMDD\n",
    "    #print(yesterday_date)\n",
    "    \n",
    "    with open(standings_file, 'r',encoding='utf-8') as f:\n",
    "        html = f.read()\n",
    "\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    links = soup.find_all(\"a\")\n",
    "    hrefs = [l.get('href') for l in links]\n",
    "    box_scores = [f\"https://www.basketball-reference.com{l}\" for l in hrefs if l and \"boxscore\" in l and '.html' in l]\n",
    "\n",
    "    filtered_urls = [url for url in box_scores if yesterday_date in url]\n",
    "\n",
    "    for url in filtered_urls:\n",
    "        save_path = os.path.join(scores_dir, url.split(\"/\")[-1])\n",
    "        \n",
    "        if os.path.exists(save_path):\n",
    "            continue\n",
    "\n",
    "        html = get_html_function(url, \"#content\")\n",
    "        \n",
    "        if not html:\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            with open(save_path, \"wb+\") as f:\n",
    "                f.write(html.encode(\"utf-8\"))\n",
    "            print(f\"Box score saved: {save_path}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to save box score: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ef336d5b-97fe-4b64-a17b-f91a15a09270",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-21 21:24:03,342 - INFO - File NBA_2025_games-january.html has been removed.\n",
      "2025-01-21 21:24:03,344 - INFO - Scraping games for: 2025, January\n",
      "2025-01-21 21:24:42,202 - INFO - Path already exists: D:\\1. Python\\1. NBA Script\\2025\\Gathering_Data\\data\\2025_standings\\NBA_2025_games-october.html\n",
      "2025-01-21 21:24:42,204 - INFO - Path already exists: D:\\1. Python\\1. NBA Script\\2025\\Gathering_Data\\data\\2025_standings\\NBA_2025_games-november.html\n",
      "2025-01-21 21:24:42,206 - INFO - Path already exists: D:\\1. Python\\1. NBA Script\\2025\\Gathering_Data\\data\\2025_standings\\NBA_2025_games-december.html\n",
      "2025-01-21 21:25:02,388 - INFO - Data for January saved.\n"
     ]
    }
   ],
   "source": [
    "next_month = current_month + 1 if current_month < 12 else 1\n",
    "next_year = current_year if next_month != 1 else current_year + 1\n",
    "\n",
    "current_month_name = calendar.month_name[current_month].lower()\n",
    "\n",
    "next_month_name = calendar.month_name[next_month].lower()\n",
    "\n",
    "# Create directories if they don't exist\n",
    "os.makedirs(STANDINGS_DIR, exist_ok=True)\n",
    "os.makedirs(SCORES_DIR, exist_ok=True)\n",
    "\n",
    "# File removal logic (customize as needed)\n",
    "file_to_remove = f\"NBA_{current_season}_games-{current_month_name}.html\"\n",
    "file_path = os.path.join(STANDINGS_DIR, file_to_remove)\n",
    "\n",
    "try:\n",
    "    if os.path.exists(file_path):\n",
    "        os.remove(file_path)\n",
    "        logging.info(f\"File {file_to_remove} has been removed.\")\n",
    "    else:\n",
    "        logging.info(f\"File {file_to_remove} does not exist.\")\n",
    "except Exception as e:\n",
    "    logging.error(f\"An error occurred: {e}\")\n",
    "\n",
    "# Scrape games for the current and next month (customize as needed)\n",
    "if today.day == 1: # and last_month:\n",
    "    scrape_season_for_month(current_season, last_month, last_month_name, STANDINGS_DIR, get_html)\n",
    "    scrape_season_for_month(current_season, next_month, next_month_name, STANDINGS_DIR, get_html)\n",
    "    #print(current_year)\n",
    "\n",
    "else:\n",
    "    scrape_season_for_month(current_season, current_month, current_month_name, STANDINGS_DIR, get_html)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fb984f00-1c4b-483d-912b-79ab48b0873d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_standings_files(standings_dir, current_season):\n",
    "    \"\"\"\n",
    "    Process standings files for a specific season.\n",
    "\n",
    "    Args:\n",
    "        standings_dir (str): Directory containing standings files.\n",
    "        current_season (int): The current NBA season year.\n",
    "    \"\"\"\n",
    "    standings_files = os.listdir(standings_dir)\n",
    "    #print(standings_files)\n",
    "\n",
    "    # Filter files for the current season\n",
    "    files = [s for s in standings_files if str(current_season) in s]\n",
    "\n",
    "    for f in files:\n",
    "        filepath = os.path.join(standings_dir, f)\n",
    "        #print(filepath)\n",
    "\n",
    "        scrape_game(filepath, SCORES_DIR, get_html)  # Assuming scrape_game is implemented\n",
    "\n",
    "# Call the function with your STANDINGS_DIR and current_season\n",
    "process_standings_files(STANDINGS_DIR, current_season)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3a6e08d7-9b7c-45a4-bae5-0e9aa6bad68b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The first game is scheduled on: Tue, Oct 22, 2024\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def get_first_game_date(standings_file):\n",
    "    \"\"\"\n",
    "    Extract the date of the first game day from the standings file.\n",
    "    \n",
    "    Args:\n",
    "        standings_file (str): Path to the standings HTML file.\n",
    "    \n",
    "    Returns:\n",
    "        str: The date of the first game, formatted as 'Day, Month Date, Year'.\n",
    "    \"\"\"\n",
    "    with open(standings_file, 'r', encoding='utf-8') as f:\n",
    "        html = f.read()\n",
    "\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    \n",
    "    # Find the first game date in the standings table\n",
    "    table = soup.find(\"table\", {\"id\": \"schedule\"})\n",
    "    \n",
    "    if not table:\n",
    "        print(f\"No schedule table found in {standings_file}.\")\n",
    "        return None\n",
    "\n",
    "    # Look for the first non-header row (actual game data)\n",
    "    first_game_row = table.find_all(\"tr\")[1]  # Skip the header row and take the first game row\n",
    "    if first_game_row:\n",
    "        game_date_tag = first_game_row.find(\"th\", {\"data-stat\": \"date_game\"})\n",
    "        if game_date_tag:\n",
    "            return game_date_tag.text.strip()  # Returns the date of the first game\n",
    "    \n",
    "    return None\n",
    "\n",
    "# Example usage\n",
    "standings_file =  os.path.join(STANDINGS_DIR, 'NBA_2025_games-october.html')  # Replace with the actual path to your file\n",
    "\n",
    "first_game_date_str = get_first_game_date(standings_file)\n",
    "if first_game_date_str:\n",
    "    print(f\"The first game is scheduled on: {first_game_date_str}\")\n",
    "else:\n",
    "    print(\"No game dates found in the file.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "333e18ea-bad5-49ac-b211-65f7a368e5c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################################################################################################################\n",
    "# PARSE DATA FROM PREVIOUS GAME DAY #\n",
    "#########################################################################################################################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9ceea5f8-f83f-4c14-9908-77a1e82e2d3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-21 21:26:41,697 - INFO - Processing file for 2025-01-20.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import logging\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Constants\n",
    "MAX_DAYS_BACK = 150\n",
    "#SRC_DIR = \"path_to_source_directory\"  # Update this to your actual source directory\n",
    "#first_game_date_str = \"2024-10-01\"  # Replace with actual start date\n",
    "\n",
    "first_game_date = datetime.strptime(first_game_date_str, \"%a, %b %d, %Y\").date()\n",
    "#first_game_date = datetime.strptime(first_game_date_str, \"%Y-%m-%d\").date()\n",
    "\n",
    "# Logging setup\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "# Function to check if a file exists\n",
    "def file_exists(date_str):\n",
    "    filename = f\"nba_games_{date_str}.csv\"\n",
    "    return os.path.isfile(os.path.join(STAT_DIR, filename))\n",
    "\n",
    "# Optimized function to find the most recent file\n",
    "def find_most_recent_file(max_days=MAX_DAYS_BACK):\n",
    "    #today = datetime.now().date()\n",
    "    for days_back in range(1, max_days + 1):\n",
    "        date_str = (today - timedelta(days=days_back)).strftime(\"%Y-%m-%d\")\n",
    "        if file_exists(date_str):\n",
    "            return date_str\n",
    "    return None\n",
    "\n",
    "# Main script\n",
    "try:\n",
    "    #today = datetime.now().date()\n",
    "    today_date = today.date()\n",
    "    if today_date < first_game_date:\n",
    "        raise RuntimeError(f\"Season has not started. Today: {today_date}, Start Date: {first_game_date}\")\n",
    "\n",
    "    most_recent_date = find_most_recent_file()\n",
    "    if most_recent_date:\n",
    "        logging.info(f\"Processing file for {most_recent_date}.\")\n",
    "        # Add your processing logic here\n",
    "    else:\n",
    "        logging.warning(\"No recent files found.\")\n",
    "except Exception as e:\n",
    "    logging.error(f\"An error occurred: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6c4f4052-e5b0-4d15-9877-4be6d2da731d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Functions\n",
    "def parse_html(box_score):\n",
    "    \"\"\"Parse HTML content from a box score file.\"\"\"\n",
    "    try:\n",
    "        with open(box_score, encoding='utf-8') as f:\n",
    "            html = f.read()\n",
    "        soup = BeautifulSoup(html, 'html.parser')\n",
    "        [s.decompose() for s in soup.select(\"tr.over_header, tr.thead\")]\n",
    "        return soup\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error parsing HTML for {box_score}: {e}\")\n",
    "        return None\n",
    "\n",
    "def read_line_score(soup):\n",
    "    \"\"\"Read line score from the soup object.\"\"\"\n",
    "    line_score = pd.read_html(StringIO(str(soup)), attrs={'id': 'line_score'})[0]\n",
    "    cols = list(line_score.columns)\n",
    "    cols[0] = \"team\"\n",
    "    cols[-1] = \"total\"\n",
    "    line_score.columns = cols\n",
    "    line_score = line_score[[\"team\", \"total\"]]\n",
    "    return line_score\n",
    "\n",
    "def read_stats(soup, team, stat):\n",
    "    \"\"\"Read team statistics from the soup object.\"\"\"\n",
    "    df = pd.read_html(StringIO(str(soup)), attrs={'id': f'box-{team}-game-{stat}'}, index_col=0)[0]\n",
    "    return df.apply(pd.to_numeric, errors=\"coerce\")\n",
    "\n",
    "def read_season_info(soup):\n",
    "    \"\"\"Extract season information from the soup object.\"\"\"\n",
    "    nav = soup.select(\"#bottom_nav_container\")[0]\n",
    "    hrefs = [a[\"href\"] for a in nav.find_all('a')]\n",
    "    return os.path.basename(hrefs[1]).split(\"_\")[0]\n",
    "\n",
    "def rename_duplicated_columns(df):\n",
    "    \"\"\"Rename duplicated columns by appending a suffix\"\"\"\n",
    "    cols = pd.Series(df.columns)\n",
    "    for dup in cols[cols.duplicated()].unique():\n",
    "        cols[cols[cols == dup].index.values.tolist()] = [dup + '_' + str(i) if i != 0 else dup for i in range(sum(cols == dup))]\n",
    "    df.columns = cols\n",
    "    return df\n",
    "\n",
    "def copy_missing_files(src_dir, dst_dir):\n",
    "    \"\"\"Copy missing files from source to destination directory.\"\"\"\n",
    "    src_files = set(os.listdir(src_dir))\n",
    "    dst_files = set(os.listdir(dst_dir))\n",
    "    diff = src_files - dst_files\n",
    "\n",
    "    for file_name in diff:\n",
    "        if not file_name.startswith('.') and not file_name.endswith('.ipynb'):\n",
    "            shutil.copy2(os.path.join(src_dir, file_name), dst_dir)\n",
    "            logging.info(f'File {file_name} copied successfully')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0ad4b328-ff22-4b6a-becc-e28fcba3303e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_nba_data():\n",
    "    \"\"\"Main function to process NBA data.\"\"\"\n",
    "    # Use the most recent date for the file\n",
    "    last_file_date = most_recent_date\n",
    "    print(f\"Processing file for: {last_file_date}\")\n",
    "\n",
    "    filename = f\"nba_games_{last_file_date}.csv\"\n",
    "\n",
    "    # Set up logging\n",
    "    logging.basicConfig(level=logging.DEBUG, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "    try:\n",
    "        # Load existing statistics\n",
    "        existing_statistics = pd.read_csv(os.path.join(STAT_DIR, filename))\n",
    "    except FileNotFoundError:\n",
    "        logging.error(f\"File {filename} not found in {STAT_DIR}.\")\n",
    "        return\n",
    "\n",
    "    base_cols = None\n",
    "    games = []\n",
    "\n",
    "    # List of all box score HTML files\n",
    "    box_scores = [os.path.join(SCORES_DIR, f) for f in os.listdir(SCORES_DIR) if f.endswith(\".html\")]\n",
    "\n",
    "    if not box_scores:\n",
    "        logging.warning(\"No box score files found in the SCORES_DIR.\")\n",
    "        return\n",
    "\n",
    "    logging.info(f\"Number of box score files found: {len(box_scores)}\")\n",
    "\n",
    "    # Process each box score\n",
    "    for box_score in box_scores:\n",
    "        try:\n",
    "            date = pd.Timestamp(os.path.basename(box_score)[:8]).date()\n",
    "            if date < pd.Timestamp(yesterday).date():\n",
    "                continue\n",
    "\n",
    "            logging.debug(f\"Processing box score: {box_score}, Date: {date}\")\n",
    "\n",
    "            soup = parse_html(box_score)\n",
    "            if soup is None:\n",
    "                continue\n",
    "\n",
    "            line_score = read_line_score(soup)\n",
    "            teams = list(line_score[\"team\"])\n",
    "            summaries = []\n",
    "\n",
    "            for team in teams:\n",
    "                basic = read_stats(soup, team, \"basic\")\n",
    "                advanced = read_stats(soup, team, \"advanced\")\n",
    "\n",
    "                totals = pd.concat([basic.iloc[-1], advanced.iloc[-1]])\n",
    "                totals.index = totals.index.str.lower()\n",
    "\n",
    "                maxes = pd.concat([basic.iloc[:-1].max(), advanced.iloc[:-1].max()])\n",
    "                maxes.index = maxes.index.str.lower() + \"_max\"\n",
    "\n",
    "                summary = pd.concat([totals, maxes])\n",
    "                if base_cols is None:\n",
    "                    base_cols = [b for b in summary.index.drop_duplicates(keep=\"first\") if \"bpm\" not in b]\n",
    "                summary = summary[base_cols]\n",
    "                summaries.append(summary)\n",
    "\n",
    "            summary = pd.concat(summaries, axis=1).T\n",
    "            game = pd.concat([summary, line_score], axis=1)\n",
    "            game[\"home\"] = [0, 1]\n",
    "\n",
    "            game_opp = game.iloc[::-1].reset_index()\n",
    "            game_opp.columns += \"_opp\"\n",
    "\n",
    "            full_game = pd.concat([game, game_opp], axis=1)\n",
    "\n",
    "            full_game[\"season\"] = read_season_info(soup)\n",
    "            full_game[\"date\"] = pd.Timestamp(os.path.basename(box_score)[:8])\n",
    "            full_game[\"won\"] = full_game[\"total\"] > full_game[\"total_opp\"]\n",
    "            games.append(full_game)\n",
    "\n",
    "            if len(games) % 100 == 0:\n",
    "                logging.info(f\"{len(games)} / {len(box_scores)} processed.\")\n",
    "\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error processing {box_score}: {e}\")\n",
    "\n",
    "    # Warning if no games were processed\n",
    "    if not games:\n",
    "        logging.warning(\"No games were played yesterday or no valid box scores were found.\")\n",
    "        return\n",
    "    else:\n",
    "        logging.info(f\"{len(games)} games were processed.\")\n",
    "\n",
    "    # If games were processed, create a DataFrame\n",
    "    games_df = pd.concat(games, ignore_index=True)\n",
    "    print(f\"Sample processed data:\\n{games_df.head(1).to_string(index=False)}\")\n",
    "\n",
    "    # Rename duplicated columns in games_df (if any)\n",
    "    games_df = rename_duplicated_columns(games_df)\n",
    "\n",
    "    # Align columns to existing statistics\n",
    "    games_df = games_df.reindex(columns=existing_statistics.columns)\n",
    "\n",
    "    # Combine new data with existing statistics\n",
    "    combined_statistics = pd.concat([existing_statistics, games_df], ignore_index=True)\n",
    "\n",
    "    # Save the combined statistics\n",
    "    file_name = f\"nba_games_{today_date}.csv\"\n",
    "    combined_statistics.to_csv(os.path.join(STAT_DIR, file_name), index=False)\n",
    "    logging.info(f\"Combined statistics saved to: {os.path.join(STAT_DIR, file_name)}\")\n",
    "\n",
    "    # Copy any missing files\n",
    "    copy_missing_files(STAT_DIR, DST_DIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "03e10b39-b814-447b-9ae5-9c2c7c427a82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file for: 2025-01-20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-21 21:27:37,952 - INFO - Number of box score files found: 632\n",
      "2025-01-21 21:27:46,070 - INFO - 8 games were processed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample processed data:\n",
      "   mp    mp   fg  fga   fg%  3p  3pa   3p%   ft  fta   ft%  orb  drb  trb  ast  stl  blk  tov   pf   pts  gmsc  +/-   ts%  efg%  3par   ftr  orb%  drb%  trb%  ast%  stl%  blk%  tov%  usg%  ortg  drtg  mp_max  mp_max  fg_max  fga_max  fg%_max  3p_max  3pa_max  3p%_max  ft_max  fta_max  ft%_max  orb_max  drb_max  trb_max  ast_max  stl_max  blk_max  tov_max  pf_max  pts_max  gmsc_max  +/-_max  ts%_max  efg%_max  3par_max  ftr_max  orb%_max  drb%_max  trb%_max  ast%_max  stl%_max  blk%_max  tov%_max  usg%_max  ortg_max  drtg_max team  total  home  index_opp  mp_opp  mp_opp  fg_opp  fga_opp  fg%_opp  3p_opp  3pa_opp  3p%_opp  ft_opp  fta_opp  ft%_opp  orb_opp  drb_opp  trb_opp  ast_opp  stl_opp  blk_opp  tov_opp  pf_opp  pts_opp  gmsc_opp  +/-_opp  ts%_opp  efg%_opp  3par_opp  ftr_opp  orb%_opp  drb%_opp  trb%_opp  ast%_opp  stl%_opp  blk%_opp  tov%_opp  usg%_opp  ortg_opp  drtg_opp  mp_max_opp  mp_max_opp  fg_max_opp  fga_max_opp  fg%_max_opp  3p_max_opp  3pa_max_opp  3p%_max_opp  ft_max_opp  fta_max_opp  ft%_max_opp  orb_max_opp  drb_max_opp  trb_max_opp  ast_max_opp  stl_max_opp  blk_max_opp  tov_max_opp  pf_max_opp  pts_max_opp  gmsc_max_opp  +/-_max_opp  ts%_max_opp  efg%_max_opp  3par_max_opp  ftr_max_opp  orb%_max_opp  drb%_max_opp  trb%_max_opp  ast%_max_opp  stl%_max_opp  blk%_max_opp  tov%_max_opp  usg%_max_opp  ortg_max_opp  drtg_max_opp team_opp  total_opp  home_opp season       date   won\n",
      "240.0 240.0 38.0 88.0 0.432 6.0 32.0 0.188 23.0 26.0 0.885 16.0 35.0 51.0 19.0 10.0  8.0 14.0 15.0 105.0   NaN  NaN 0.528 0.466 0.364 0.295  33.3  67.3  51.0  50.0  10.4  13.6  12.3 100.0 109.1 114.3     NaN     NaN    12.0     24.0      0.8     3.0      8.0      0.5     8.0      9.0      1.0      8.0      8.0     15.0      4.0      3.0      7.0      4.0     5.0     33.0      40.6      2.0    0.857       0.8       1.0      0.6      23.8      28.6      21.4      20.5       5.3      16.9      32.2      33.3     187.0     126.0  DAL    105     0          1   240.0   240.0    40.0     98.0    0.408    17.0     39.0    0.436    13.0     18.0    0.722     17.0     32.0     49.0     28.0     10.0      7.0     13.0    16.0    110.0       NaN      NaN    0.519     0.495     0.398    0.184      32.7      66.7      49.0      70.0      10.4      12.5      10.9     100.0     114.3     109.1         NaN         NaN         8.0         21.0        0.667         5.0         10.0        0.625         3.0          4.0          1.0          7.0          6.0         13.0          9.0          2.0          3.0          3.0         4.0         23.0          18.0         11.0        0.731         0.731         0.667        0.333          21.7          30.1          21.0          55.4           5.4           8.7          20.0          26.4         159.0         115.0      CHO        110         1   2025 2025-01-20 False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-21 21:27:48,675 - INFO - Combined statistics saved to: D:\\1. Python\\1. NBA Script\\2025\\Gathering_Data\\Whole_Statistic\\nba_games_2025-01-21.csv\n",
      "2025-01-21 21:27:48,729 - INFO - File nba_games_2025-01-20.csv copied successfully\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    process_nba_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48ebdf0c-eab8-449c-8cc0-f996dd27ab8d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e055b2a8-64d4-4db8-bf91-f2b2e0fa2bf2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
