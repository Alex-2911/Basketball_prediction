# -*- coding: utf-8 -*-
"""
NBA Game Prediction Script (2025‑26 Season)

This script (Script 3 of 5) calculates predictions for the next NBA game day
based on historical data, rolling averages, and a LightGBM model.  It reads
the latest game schedule generated by the ``2_get_data_next_game_day``
script, merges it with season statistics and odds data, and writes a
prediction CSV into the ``PREDICTION_DIR`` defined in ``nba_utils_2026``.

Key features / changes from the 2025 version:

* Imports from ``nba_utils_2026`` instead of ``nba_utils``.  The
  ``nba_utils_2026`` module should expose the same interface but point to
  the correct directories for the 2025‑26 season (labeled 2026 on
  Basketball‑Reference).
* Reads the odds API key from the ``ODDS_API_KEY`` environment variable
  instead of hard‑coding a value.  This makes it easier to store
  sensitive keys in GitHub secrets.

Example usage::

    # Ensure ``2_get_data_next_game_day_2026.py`` has been run to produce the games_df CSV
    python 3_predict_next_game_day_2026.py

Ensure that ``1_get_data_previous_game_day.py`` and
``2_get_data_next_game_day_2026.py`` have been executed beforehand so
that the necessary data files are present.
"""

import os
import glob
import logging
from datetime import datetime
from typing import Tuple, List, Dict

import pandas as pd
import numpy as np
from sklearn.preprocessing import MinMaxScaler
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score
import lightgbm as lgb
import requests
from urllib3.util.retry import Retry
from requests.adapters import HTTPAdapter

# Hard-coded API key for the-odds-api.com.
# If you update your API key, change the value below.
API_KEY = "8e9d506f8573b01023028cef1bf645b5"

# Import shared utilities from the 2026 version
from nba_utils_2026 import (
    CURRENT_SEASON,
    ROLLING_WINDOW_SIZE,
    get_current_date,
    get_directory_paths,
    get_latest_file,
    preprocess_nba_data,
    calculate_rolling_averages,
    add_next_game_columns,
    impute_prob,
    am_to_dec,
)

# Configure logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')


def setup_paths_and_files() -> Tuple[Dict[str, str], Tuple[datetime, str, str], str, str, pd.DataFrame]:
    """Set up directory paths and locate the latest statistics and games files.

    Returns:
        tuple: (paths, (today, today_str, today_str_format), df_path_stat, games_df_path, games_df)
    """
    # Use current date without offset for prediction day
    today, today_str, today_str_format = get_current_date(0)
    paths = get_directory_paths()

    # Paths for statistics and games
    stat_dir = paths['STAT_DIR']
    next_game_dir = paths['NEXT_GAME_DIR']
    prediction_dir = paths['PREDICTION_DIR']

    # Statistics file: produced by 1_get_data_previous_game_day
    df_path_stat = os.path.join(stat_dir, f"nba_games_{today_str_format}.csv")
    if not os.path.exists(df_path_stat):
        logging.info(f"Statistics file not found for today ({today_str_format}); searching for latest file…")
        # If today's stats are missing, use the most recent file in the directory
        stat_files = sorted(glob.glob(os.path.join(stat_dir, "nba_games_*.csv")))
        if stat_files:
            df_path_stat = stat_files[-1]
            logging.info(f"Using latest statistics file: {df_path_stat}")
        else:
            raise FileNotFoundError(f"No statistics files found in {stat_dir}")

    # Locate the most recent games schedule file from the Next_Game directory
    games_df_path = get_latest_file(next_game_dir, prefix="games_df_", ext=".csv")
    if not games_df_path:
        raise FileNotFoundError(f"No games_df_*.csv found in {next_game_dir}")

    # Read the games schedule; drop the index column if present
    games_df = pd.read_csv(games_df_path)
    if 'Unnamed: 0' in games_df.columns:
        games_df = games_df.drop(columns=['Unnamed: 0'])
    logging.info(f"Loaded game schedule from {games_df_path} with {len(games_df)} games")

    return paths, (today, today_str, today_str_format), df_path_stat, games_df_path, games_df


def load_and_preprocess_data(df_path_stat: str, games_df: pd.DataFrame) -> Tuple[pd.DataFrame, List[str], Dict[str, str]]:
    """Load historical NBA statistics and compute rolling averages.

    Args:
        df_path_stat (str): Path to the statistics CSV file.
        games_df (DataFrame): Upcoming games schedule.

    Returns:
        tuple: (preprocessed DataFrame, selected numeric columns, mapping of rolling columns)
    """
    # Preprocess data (clean, sort, add target column, handle missing values)
    df = preprocess_nba_data(df_path_stat)

    # Exclude non-numeric columns from scaling
    removed_columns = ["season", "date", "won", "target", "team", "team_opp"]
    selected_columns = df.columns[~df.columns.isin(removed_columns)]

    # Normalize selected features
    scaler = MinMaxScaler()
    df[selected_columns] = scaler.fit_transform(df[selected_columns])

    # Compute rolling averages over ROLLING_WINDOW_SIZE games
    df_rolling = calculate_rolling_averages(df[selected_columns.tolist() + ["won", "team", "season"]], ROLLING_WINDOW_SIZE)
    rolling_cols = {col: f"{col}_{ROLLING_WINDOW_SIZE}" for col in df_rolling.columns if col not in ['team', 'season']}
    df_rolling.rename(columns=rolling_cols, inplace=True)

    # Merge original data with rolling averages and drop NaNs
    df = pd.concat([df.reset_index(drop=True), df_rolling.reset_index(drop=True)], axis=1).dropna()

    # Append next-game info (home, opponent, next date)
    df = add_next_game_columns(df)

    return df, selected_columns.tolist(), rolling_cols


def prepare_training_and_prediction_data(
    df: pd.DataFrame,
    games_df: pd.DataFrame,
    game_day: str
) -> Tuple[pd.DataFrame, pd.DataFrame, List[str]]:
    """Construct training and prediction datasets.

    Args:
        df (DataFrame): Combined statistics and rolling data.
        games_df (DataFrame): Upcoming games schedule.
        game_day (str): Date (YYYY-MM-DD) of the games for prediction.

    Returns:
        tuple: (training DataFrame, prediction DataFrame, list of columns to exclude from features)
    """
    logging.info("Preparing training and prediction datasets…")

    # Extract records for easier lookup
    records = df.to_dict('records')
    team_latest: Dict[str, Dict] = {}
    for rec in records:
        team = str(rec.get('team'))
        date = rec.get('date')
        if not team:
            continue
        # Parse date if it's a string
        if isinstance(date, str):
            try:
                date = pd.to_datetime(date)
            except Exception:
                continue
        if team not in team_latest or date > team_latest[team]['date']:
            team_latest[team] = {'record': rec, 'date': date}

    # Historical matchups for training
    historical_rows = []
    for rec in records:
        # Skip future games (target=2)
        if rec.get('target') == 2:
            continue
        team = rec.get('team')
        opp = rec.get('team_opp')
        if not team or not opp:
            continue
        # Find opponent record
        opp_rec_entry = team_latest.get(str(opp))
        if not opp_rec_entry:
            continue
        opp_rec = opp_rec_entry['record']
        # Build feature dict
        row = {
            'team_x': str(team),
            'team_y': str(opp),
            'target': rec.get('target', 0),
            'home': rec.get('home', 0),
        }
        for col, val in rec.items():
            if col in ['team', 'team_opp', 'target', 'home']:
                continue
            row[f"{col}_x"] = val
        for col, val in opp_rec.items():
            if col in ['team', 'team_opp', 'target', 'home']:
                continue
            row[f"{col}_y"] = val
        historical_rows.append(row)

    train_df = pd.DataFrame(historical_rows)
    logging.info(f"Training dataset size: {len(train_df)}")

    # Prediction rows for upcoming games
    prediction_rows = []
    for _, game in games_df.iterrows():
        home_team = str(game['home_team'])
        away_team = str(game['away_team'])
        home_entry = team_latest.get(home_team)
        away_entry = team_latest.get(away_team)
        if not home_entry or not away_entry:
            logging.warning(f"Missing data for {home_team} vs {away_team}; skipping")
            continue
        pred_row = {
            'team_x': home_team,
            'team_y': away_team,
            'target': 2,
            'home': 1,
            'date_next': game_day,
        }
        for col, val in home_entry['record'].items():
            if col in ['team', 'team_opp', 'target', 'home']:
                continue
            pred_row[f"{col}_x"] = val
        for col, val in away_entry['record'].items():
            if col in ['team', 'team_opp', 'target', 'home']:
                continue
            pred_row[f"{col}_y"] = val
        prediction_rows.append(pred_row)

    pred_df = pd.DataFrame(prediction_rows)
    logging.info(f"Prediction dataset size: {len(pred_df)}")

    # List of columns to exclude when selecting features
    removed_columns = [
        'team_x', 'team_y', 'target', 'home', 'date', 'date_next',
        'season', 'won', 'team', 'team_opp'
    ]
    return train_df, pred_df, removed_columns


def train_model(train_df: pd.DataFrame, removed_columns: List[str]) -> Tuple[lgb.LGBMClassifier, List[str]]:
    """Train a LightGBM model using historical matchups.

    Args:
        train_df: DataFrame with historical matchups and outcome.
        removed_columns: Columns that should not be used as features.

    Returns:
        tuple: (trained model, list of feature names)
    """
    logging.info(f"Training data contains {len(train_df)} rows and {len(train_df.columns)} columns")
    if len(train_df) < 10:
        raise ValueError("Insufficient training data; need at least 10 historical games")

    # Identify numeric feature columns
    to_drop = set(removed_columns)
    # Remove any non-numeric or string columns
    for col in train_df.columns:
        if col in to_drop:
            continue
        if train_df[col].dtype == object:
            try:
                pd.to_datetime(train_df[col].iloc[0])
                to_drop.add(col)
            except Exception:
                to_drop.add(col)
        elif not pd.api.types.is_numeric_dtype(train_df[col]):
            to_drop.add(col)

    feature_cols = [c for c in train_df.columns if c not in to_drop]
    if not feature_cols:
        raise ValueError("No valid numeric features available for training")

    X = train_df[feature_cols].values
    y = train_df['target'].values

    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

    params = {
        'objective': 'binary',
        'metric': 'auc',
        'num_leaves': 10,
        'learning_rate': 0.1,
        'feature_fraction': 0.9,
        'bagging_fraction': 0.9,
        'bagging_freq': 10,
        'boosting_type': 'gbdt',
        'verbosity': -1,
        'random_state': 42,
        'lambda_l1': 0.5,
        'lambda_l2': 0.5,
        'max_depth': 7,
        'min_child_weight': 5
    }

    model = lgb.LGBMClassifier(**params)
    model.fit(X_train, y_train)
    pred_test = model.predict(X_test)
    accuracy = accuracy_score(y_test, pred_test)
    logging.info(f"LightGBM model trained with accuracy: {accuracy:.2%}")

    # Feature importances (optional)
    importances = model.feature_importances_
    feat_imp = sorted(zip(feature_cols, importances), key=lambda x: x[1], reverse=True)
    top_features = feat_imp[: min(10, len(feat_imp))]
    logging.info("Top feature importances (first 10):")
    for i, (name, score) in enumerate(top_features, 1):
        logging.info(f"  {i}. {name}: {score}")

    return model, feature_cols


def predict_upcoming_games(
    model: lgb.LGBMClassifier,
    pred_df: pd.DataFrame,
    feature_cols: List[str],
    games_df: pd.DataFrame,
    game_day: str
) -> pd.DataFrame:
    """Generate win probability predictions for upcoming games.

    Args:
        model: Trained LightGBM model.
        pred_df: Prediction feature DataFrame.
        feature_cols: Columns used for training and prediction.
        games_df: Schedule of upcoming games.
        game_day: Date of games (YYYY-MM-DD).

    Returns:
        DataFrame: Predictions with home team probability.
    """
    if pred_df.empty:
        logging.warning("No games to predict")
        return pd.DataFrame()
    X_pred = pred_df[feature_cols].values
    proba = model.predict_proba(X_pred)[:, 1]
    results = []
    for i, (_, row) in enumerate(pred_df.iterrows()):
        results.append({
            'home_team': row['team_x'],
            'away_team': row['team_y'],
            'home_team_prob': float(proba[i]),
            'result': 0,
            'date': game_day,
        })
    return pd.DataFrame(results)


def get_session() -> requests.Session:
    """Create a requests session with retry configuration."""
    session = requests.Session()
    retries = Retry(total=3, backoff_factor=0.5, status_forcelist=[429, 500, 502, 503, 504])
    session.mount("https://", HTTPAdapter(max_retries=retries))
    return session


def fetch_odds(games_df: pd.DataFrame, api_key: str, preferred: List[str] = None) -> pd.DataFrame:
    """Fetch head-to-head odds from the-odds-api.com.

    Args:
        games_df: Schedule of upcoming games.
        api_key: API key for the-odds-api.com.
        preferred: Optional list of preferred bookmakers by key (e.g., draftkings).

    Returns:
        DataFrame: Odds data merged by (home_team, away_team).
    """
    # Mapping of full team names to abbreviations for odds API
    full_to_abbrev = {
        "Atlanta Hawks": "ATL", "Boston Celtics": "BOS", "Brooklyn Nets": "BRK",
        "Charlotte Hornets": "CHA", "Chicago Bulls": "CHI", "Cleveland Cavaliers": "CLE",
        "Dallas Mavericks": "DAL", "Denver Nuggets": "DEN", "Detroit Pistons": "DET",
        "Golden State Warriors": "GSW", "Houston Rockets": "HOU", "Indiana Pacers": "IND",
        "Los Angeles Clippers": "LAC", "LA Clippers": "LAC", "Los Angeles Lakers": "LAL",
        "Memphis Grizzlies": "MEM", "Miami Heat": "MIA", "Milwaukee Bucks": "MIL",
        "Minnesota Timberwolves": "MIN", "New Orleans Pelicans": "NOP", "New York Knicks": "NYK",
        "Oklahoma City Thunder": "OKC", "Orlando Magic": "ORL", "Philadelphia 76ers": "PHI",
        "Phoenix Suns": "PHX", "Portland Trail Blazers": "POR", "Sacramento Kings": "SAC",
        "San Antonio Spurs": "SAS", "Toronto Raptors": "TOR", "Utah Jazz": "UTA",
        "Washington Wizards": "WAS"
    }
    session = get_session()
    response = session.get(
        "https://api.the-odds-api.com/v4/sports/basketball_nba/odds",
        params={
            "apiKey": api_key,
            "regions": "us",
            "markets": "h2h",
            "oddsFormat": "american",
        },
        timeout=10,
    )
    response.raise_for_status()
    data = response.json()
    # Build a lookup: (home_abbr, away_abbr) -> (price_home, price_away)
    lookup = {}
    for event in data:
        home_full = event.get("home_team")
        away_full = event.get("away_team")
        home_abbr = full_to_abbrev.get(home_full)
        away_abbr = full_to_abbrev.get(away_full)
        if not home_abbr or not away_abbr:
            continue
        bookmakers = event.get("bookmakers", [])
        chosen = None
        if preferred:
            for p in preferred:
                chosen = next((b for b in bookmakers if b.get("key") == p), None)
                if chosen:
                    break
        if not chosen and bookmakers:
            chosen = bookmakers[0]
        market = next((m for m in chosen.get("markets", []) if m.get("key") == "h2h"), None)
        if not market:
            continue
        prices = {}
        for outcome in market.get("outcomes", []):
            name = outcome.get("name")
            abbr = full_to_abbrev.get(name)
            if abbr:
                prices[abbr] = outcome.get("price")
        lookup[(home_abbr, away_abbr)] = (prices.get(home_abbr), prices.get(away_abbr))
    odds_rows = []
    for _, gm in games_df.iterrows():
        h, a = gm['home_team'], gm['away_team']
        o1, o2 = lookup.get((h, a), (None, None))
        if o1 is None or o2 is None:
            logging.warning(f"No odds found for {h} vs {a}")
        odds_rows.append({"home_team": h, "away_team": a, "odds 1": o1, "odds 2": o2})
    return pd.DataFrame(odds_rows)


def merge_predictions_with_odds(preds, odds):
    df = preds.merge(odds, on=["home_team","away_team"], how="left")

    # Coerce odds to numeric; invalid → NaN
    for col in ["odds 1", "odds 2"]:
        if col in df.columns:
            df[col] = pd.to_numeric(df[col], errors="coerce")

    # Implied probabilities (robust to NaN)
    df["imp_prob_home"] = df["odds 1"].apply(impute_prob)
    df["imp_prob_away"] = df["odds 2"].apply(impute_prob)

    # Value metrics only when implied probs exist
    df["value_home"] = np.where(
        df["imp_prob_home"].notna(),
        df["home_team_prob"] - df["imp_prob_home"],
        np.nan
    )
    df["value_away"] = np.where(
        df["imp_prob_away"].notna(),
        (1.0 - df["home_team_prob"]) - df["imp_prob_away"],
        np.nan
    )
    return df



def prepare_final_output(
    predictions: pd.DataFrame,
    odds_df: pd.DataFrame,
    game_day: str
) -> Tuple[pd.DataFrame, pd.DataFrame]:
    """Create final prediction DataFrame with decimal odds and value columns."""
    final_df = merge_predictions_with_odds(predictions, odds_df)
    # Prepare home_team_preds with decimal odds and round to 2 decimals
    home_team_preds = predictions.merge(
        odds_df[['home_team', 'away_team', 'odds 1', 'odds 2']], on=['home_team', 'away_team'], how='left'
    )
    home_team_preds["odds 1"] = home_team_preds["odds 1"].apply(am_to_dec)
    home_team_preds["odds 2"] = home_team_preds["odds 2"].apply(am_to_dec)
    home_team_preds["odds 1"] = home_team_preds["odds 1"].apply(lambda x: round(x, 2) if pd.notnull(x) else x)
    home_team_preds["odds 2"] = home_team_preds["odds 2"].apply(lambda x: round(x, 2) if pd.notnull(x) else x)
    # Set result and date
    home_team_preds = home_team_preds.assign(result=0, date=game_day)
    return final_df, home_team_preds


def save_predictions(
    home_team_preds: pd.DataFrame,
    directory: str,
    today_str_format: str
) -> str:
    """Save the prediction DataFrame to a CSV file."""
    filename = f"nba_games_predict_{today_str_format}.csv"
    filepath = os.path.join(directory, filename)
    os.makedirs(directory, exist_ok=True)
    if os.path.exists(filepath):
        logging.info(f"Prediction file already exists: {filepath}")
    else:
        cols = ["home_team", "away_team", "home_team_prob", "result", "odds 1", "odds 2", "date"]
        home_team_preds[cols].to_csv(filepath, index=False)
        logging.info(f"Saved predictions to {filepath}")
    return filepath


def main() -> str:
    """Execute the prediction pipeline."""
    # Setup paths and read data
    paths, (today, today_str, today_str_format), df_path_stat, games_df_path, games_df = setup_paths_and_files()
    # Load and preprocess season statistics
    df, selected_columns, rolling_cols = load_and_preprocess_data(df_path_stat, games_df)
    
    # Normalize team codes across datasets (fixes PHO↔PHX, BKN↔BRK, etc.)
    from nba_utils_2026 import normalize_team_codes_inplace

    normalize_team_codes_inplace(df, ["team", "team_opp"])
    normalize_team_codes_inplace(games_df, ["home_team", "away_team"])

    
    # Prepare training and prediction datasets
    train_df, pred_df, removed_cols = prepare_training_and_prediction_data(df, games_df, today_str_format)
    # Train model
    model, feature_cols = train_model(train_df, removed_cols)
    # Generate predictions for upcoming games
    home_team_preds_ml = predict_upcoming_games(model, pred_df, feature_cols, games_df, today_str_format)
    # Fetch odds using the hard-coded API key defined at the top of the script.
    odds_df = fetch_odds(home_team_preds_ml, API_KEY, preferred=["draftkings", "fanduel"])
    # Merge predictions with odds and compute value
    final_df, home_team_preds = prepare_final_output(home_team_preds_ml, odds_df, today_str_format)
    # Save predictions to file
    output_path = save_predictions(home_team_preds, paths['PREDICTION_DIR'], today_str_format)
    # Log final output path
    logging.info(f"Prediction CSV saved to {output_path}")
    return output_path


if __name__ == "__main__":
    try:
        main()
    except Exception:
        logging.exception("An unexpected error occurred during prediction.")
    finally:
        # Keep the console window open so the user can read the logs.  In a non-interactive
        # environment (e.g. GitHub Actions), input() will raise EOFError, which we catch and ignore.
        try:
            input("Prediction complete. Press Enter to close this window...")
        except EOFError:
            pass